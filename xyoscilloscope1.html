<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Visualizer Shader</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: black;
        }
        canvas {
            display: block;
        }
        input {
            position: absolute;
            top: 20px;
            left: 20px;
            z-index: 10;
        }
    </style>
</head>
<body>
    <input type="file" id="audio-upload" accept="audio/*">
    <canvas id="glcanvas"></canvas>

    <script id="fragment-shader" type="x-shader/x-fragment">
        precision mediump float;
        uniform vec2 iResolution;
        uniform float iTime;
        uniform sampler2D iChannel0;

        #define VISUAL_LINE_COLOR vec3(0.4, 1.0, 0.4)
        #define VISUAL_LINE_BLUR 2.0
        #define VISUAL_LINE_BRIGHTNESS 2000.0
        #define VISUAL_ITERATIONS 512

        float map(float a, float b, float x) {
            return (x - a) / (b - a);
        }

        float saturate(float x) {
            return clamp(x, 0.0, 1.0);
        }

        vec2 pointTex(float t) {
            vec2 p = texture2D(iChannel0, vec2(t, 0.5)).xy;
            p = (p * 4.0) - 2.0;
            return p;
        }

        void mainImage(out vec4 fragColor, in vec2 fragCoord) {
            vec2 uv = fragCoord / iResolution.xy * 2.0 - 1.0;
            uv.x *= iResolution.x / iResolution.y;
            
            float v = 0.0;
            vec2 lp = pointTex(0.0), cp;
            float fv = 1.0 / float(VISUAL_ITERATIONS);

            for(int i = 0; i < VISUAL_ITERATIONS; ++i) {
                float k = float(i) * fv;
                cp = pointTex(k);
                v += length(lp - uv) + length(cp - uv);
                lp = cp;
            }

            fragColor = vec4(VISUAL_LINE_COLOR * v * 0.01, 1.0);
        }

        void main() {
            mainImage(gl_FragColor, gl_FragCoord.xy);
        }
    </script>

    <script>
        let canvas = document.getElementById("glcanvas");
        let gl = canvas.getContext("webgl");

        if (!gl) {
            alert("WebGL not supported in this browser.");
        }

        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        let shaderScript = document.getElementById("fragment-shader").textContent;
        let fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
        gl.shaderSource(fragmentShader, shaderScript);
        gl.compileShader(fragmentShader);

        if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
            console.error("ERROR compiling fragment shader!", gl.getShaderInfoLog(fragmentShader));
            return;
        }

        let program = gl.createProgram();
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);

        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            console.error("ERROR linking program!", gl.getProgramInfoLog(program));
            return;
        }

        gl.useProgram(program);

        let resolutionUniformLocation = gl.getUniformLocation(program, "iResolution");
        gl.uniform2f(resolutionUniformLocation, canvas.width, canvas.height);

        let timeUniformLocation = gl.getUniformLocation(program, "iTime");

        let texture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

        document.getElementById("audio-upload").addEventListener("change", function (e) {
            let audioFile = e.target.files[0];
            let audioContext = new AudioContext();
            let reader = new FileReader();

            reader.onload = function () {
                audioContext.decodeAudioData(reader.result, function (buffer) {
                    let data = buffer.getChannelData(0);
                    let textureData = new Float32Array(data.length);
                    for (let i = 0; i < data.length; i++) {
                        textureData[i] = data[i];
                    }

                    gl.bindTexture(gl.TEXTURE_2D, texture);
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.LUMINANCE, data.length, 1, 0, gl.LUMINANCE, gl.FLOAT, textureData);
                });
            };
            reader.readAsArrayBuffer(audioFile);
        });

        function render(time) {
            gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

            gl.uniform1f(timeUniformLocation, time * 0.001);

            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            requestAnimationFrame(render);
        }

        render();
    </script>
</body>
</html>